{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94276fe8",
   "metadata": {},
   "source": [
    "# In-class exercise 6a: Corpus Pre-processing and Dictionary Method\n",
    "\n",
    "## The Moral Foundation Dictionary \n",
    "\n",
    "In this exercise, we will practice pre-processing natural language and use a very simple dictionary method to explore to what extend the American democrats and republican presidential candidates appeal to different **moral values**. \n",
    "\n",
    "\n",
    "Before that, please install two additional packages into our datamanagement environment: `langdetect` and `fastparquet`. You can do so by running the following command in a code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da70b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install langdetect\n",
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d1fad",
   "metadata": {},
   "source": [
    "### The moral foundations\n",
    "\n",
    "A group of psychologists - notably Jonathan Halddt and Jesse Graham - noticed that human beings across different culture background often value similar virtues - such as careness, fairness, loyalty and authority - and theorized that these common themes might have been essential for humanity's survival. They developed the **moral foundation theory** (https://moralfoundations.org) which established the five pillers of morality that are shared among cultures: \n",
    "\n",
    "1. **Careness**: sympathy, mutual aid and nurturance. It helps human to care about the small and the weak and survives as a group.\n",
    "2. **Fairness**: reciprocity and proportionality. It encourages production and enables justice and right. \n",
    "3. **Loyalty/In-group**: feeling like belonging to a group or a tribe, a difference between us and them. It encourages contributing to the collective and formation of coalitions.\n",
    "4. **Authority**: observance of a storng leader, doing as orders command. It makes cooperation more efficient. \n",
    "5. **Purity/Sanctity**: disgust of filth and contamination - including physical ones, such as blood or dead body,  and religious ones ,such as incest. It improves the sanitary condition in human habitat and promotes self-control and spirituality.\n",
    "\n",
    "We call the words that describe things promoted by the five ideas \"virtues\" and the opposites - negligence, freeloading, betrayal, disobedience and sacrilege - \"vices\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f6f07f",
   "metadata": {},
   "source": [
    "Researchers in social sciences often notice that different political factions appeal to different moral foundations. In the context of American politics for example, the Democrats emphasizes more careness and fairness, while the Republicans emphasizes loyalty and authority. \n",
    "\n",
    "We will work on a small exercise today, inspired by but not identical with Hackenburg, Brady and Tsakiris (2023, https://doi.org/10.1093/pnasnexus/pgad189). The data are downloaded from OSF (10.17605/OSF.IO/FZ6KP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "568cbbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/huangyuchen/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/huangyuchen/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/huangyuchen/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/huangyuchen/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import everything we need today \n",
    "\n",
    "# The basics\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# NLP tool kit\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt_tab')      \n",
    "nltk.download('wordnet')    \n",
    "nltk.download('omw-1.4') \n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk.corpus import wordnet\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Language detection \n",
    "import langdetect\n",
    "\n",
    "import fastparquet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b4a4a",
   "metadata": {},
   "source": [
    "## Exercise 1: Import The Moral Dictionary \n",
    "\n",
    "Some words describing each virtue and vice is included data/moral_foundation_dictionary. \n",
    "\n",
    "1. Open the `mfd2.0.dic` in this folder with a text reader (VSC works well) and observe the structure. \n",
    "2. Read this document into python, remove the headers (line 1 to 12) so that it can be converted to a data frame. \n",
    "2. Convert `mfd2.0.dic` in python to a pandas data frame, where one column is the word, another column is the code representing its categories (e.g. \"1\" for care.virtue, 2 for care.vice). Name the two columns `word` and `category`. \n",
    "3. Replace the category column with its label from the MFD, so that instead of 1, the column now has a value of \"care.virtue\" (see exercise in the pandas session for reference)\n",
    "4. Not necessary but good data practice: put the columns to the good category (str for word and categorical for category.)\n",
    "\n",
    "\n",
    "Hints: \n",
    "- You might meet all kinds of text materials in different formats in NLP exercises. Most of them can be opened by VSC as text, and read as text. `read().splitlines()` and `read().split()` are your good friends. \n",
    "- Here we are working in English so special characters are not a problem. If you are working with French, its a good practice to always read with the accurated encoding (e.f. \"utf-8\") to make sure that accented characters are visible. \n",
    "- \"\\t\" means space and \"\\n\" means line skip. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b57c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports - here are some useful paths\n",
    "this_dir = Path(\".\")\n",
    "moral_foundation = this_dir / \"data\" / \"moral_foundation_dictionary\"\n",
    "word_list = moral_foundation / \"mfd2.0.dic\"\n",
    "word_list.exists()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f18af",
   "metadata": {},
   "source": [
    "## Exercise 2: Stemming/Lemmatizing the words\n",
    "\n",
    "### Try stemming and lemmatizing\n",
    "We notice that each word comes in different grammar forms (such as 'caring', 'cared' and 'cares'). We would like to shrink the size of our dictionary, so that any program would run faster. \n",
    "\n",
    "For that we have two choices: stemming and lemmatizing. \n",
    "\n",
    "1. Produce a vector of stemmed moral keywords - be careful not to overwrite the column in the data frame yet. We will use the `SnowballStemmer` from `nltk` as in the lecture. \n",
    "2. Produce a vector of lemmatized moral keywords - be careful not to overwrite the column in the data frame yet. We will use the `WordNetLemmatizer` from `nltk` as in the lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa0571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71fa7728",
   "metadata": {},
   "source": [
    "### (Might be a problem): why is my lemmatizer not working? \n",
    "Now, you might notice that the lemmatizer is \"barely altering\" your words! For example, \"caring\" was not changed to \"care\". Why is this? \n",
    "\n",
    "Try to find out the solution on your favoriate search engine. Hint: it has something to do with how lemmatizer understand the word - the part-of-speech that it assigned to the word. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da04e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb01c975",
   "metadata": {},
   "source": [
    "### Pick an option \n",
    "\n",
    "Given the results and our goal (count occurences of these words in natural speech = Twitter), do you prefer stemming or lemmatizing? \n",
    "\n",
    "There is no correct answer, just explain your logic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2239e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad509542",
   "metadata": {},
   "source": [
    "### We adopt the lemmatizer \n",
    "\n",
    "For the rest of the exercise we will keep the lemmatizer. Please replace the `word` column of your data frame `mfd` with the lemmatized version, and then drop the duplicates. (`drop_duplicates()` is helpful here )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3410a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ad9996c",
   "metadata": {},
   "source": [
    "## Exercise 3: Importing Tweets from presidential candidates \n",
    "\n",
    "We would like to pre-process our presendital candidate tweets right now! We are looking at 4 sets of tweets: Biden, Clinton, Trump 2016 and Trump 2020. Similarly, we would like to read it into a pandas DF with the name of the candidate and the tweet.\n",
    "\n",
    "We would ideally like to have a pandas dataframe with three columns: `candidate`, `year` and `original_text`. We will call the dataframe `all_tweets`.\n",
    "\n",
    "Here is how I proceeded to read the files, please complete the code so that you manage to read the dataframe (hint: look at what variables have not been defined) but feel free to do otherwise! \n",
    "\n",
    "1. create an empty data frame with the desired columns. \n",
    "2. iterrate files in the directorate \n",
    "3. for each directorate, extracte \"2016\" or \"2020\" in the file name for year and the name of the candidate. Put them in variables to be inserted later. \n",
    "4. read the file by line and convert it to a dataframe. \n",
    "5. create the year and candidate columns using stored variables. \n",
    "6. append (`pd.concat`) the dataframe read from one file to the main file `all_tweets`. \n",
    "\n",
    "\n",
    "P.S. Some of Trump's tweet looks \"unfinished\" in the original file. This is the way I found it at download - it is ok for the purpose of the exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885ac83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>year</th>\n",
       "      <th>candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just landed in Iowa - speaking soon!</td>\n",
       "      <td>2016</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is time to</td>\n",
       "      <td>2016</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you!</td>\n",
       "      <td>2016</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will be on at 7:02 A.M.  Enjoy.</td>\n",
       "      <td>2016</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17288</th>\n",
       "      <td>\"Hillary Clinton is the better candidate to ta...</td>\n",
       "      <td>2016</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17289</th>\n",
       "      <td>72 years after  let's not just eulogize the br...</td>\n",
       "      <td>2016</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17290</th>\n",
       "      <td>Donald Trump should come out of the towers he ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17291</th>\n",
       "      <td>bigoted comments about a Latino judge are so ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17292</th>\n",
       "      <td>We just won Puerto Rico! ¡Gracias a la Isla de...</td>\n",
       "      <td>2016</td>\n",
       "      <td>hillary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17293 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           original_text  year candidate\n",
       "0                   Just landed in Iowa - speaking soon!  2016     trump\n",
       "1                                         It is time to   2016     trump\n",
       "2                                          Thank you!     2016     trump\n",
       "3                        Will be on at 7:02 A.M.  Enjoy.  2016     trump\n",
       "4                                                         2016     trump\n",
       "...                                                  ...   ...       ...\n",
       "17288  \"Hillary Clinton is the better candidate to ta...  2016   hillary\n",
       "17289  72 years after  let's not just eulogize the br...  2016   hillary\n",
       "17290  Donald Trump should come out of the towers he ...  2016   hillary\n",
       "17291   bigoted comments about a Latino judge are so ...  2016   hillary\n",
       "17292  We just won Puerto Rico! ¡Gracias a la Isla de...  2016   hillary\n",
       "\n",
       "[17293 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for dir in tweet_data.iterdir():\n",
    "\n",
    "    if dir.name.find(\"2016\") > 0 : \n",
    "        # if there is 2016, we should give a value to some variable called 2016\n",
    "\n",
    "    for candidate in ['biden', 'hillary', 'trump']:\n",
    "        if dir.name.find(candidate) > 0 :\n",
    "            person = candidate \n",
    "\n",
    "    with open(dir, encoding='utf-8') as file:\n",
    "        tweets = file.read().splitlines()\n",
    "\n",
    "    tweets = pd.DataFrame(tweets)\n",
    "    tweets.columns = ['original_text']\n",
    "    tweets['candidate'] = # give the value person here \n",
    "    tweets['year'] = # give the value year here\n",
    "    \n",
    "    all_tweets = pd.concat([all_tweets, tweets ])\n",
    "    \n",
    "# Put them into the correct category - to do \n",
    "\n",
    "# don't foget to reset index! - to do "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4cdf0c",
   "metadata": {},
   "source": [
    "(we can insert an exercise on sentiment analysis or part-of-word here, we would also add purging spanish) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a21ea",
   "metadata": {},
   "source": [
    "## Exercise 4: Pre-processing the tweets\n",
    "\n",
    "We would like to do the following things: \n",
    "- put everything to lower case\n",
    "- remove all non-alphabetic things\n",
    "- remove punctuation \n",
    "- remove stopwords\n",
    "- lemmatizing \n",
    "\n",
    "1. Please create a function called `noralize_text` that would take a document (here, a tweet) and return a list of lemmatized words. Feel free to copy-paste from the lecture and see what happens. \n",
    "2. Then, `apply` it to the column `original_text` to generate a column called `processed_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9cfdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52bc7658",
   "metadata": {},
   "source": [
    "### Bonus: Can I adapt the off-the-shelf pre-processing function to better fit our use case? \n",
    "\n",
    "If you had copy-pasted the function made by Malka in the lecture, you might want to circle a bit in the dataset and see whether it has problems - whether it failed to process certain words that should be processed. \n",
    "\n",
    "Here are some of the questions that I noticed: \n",
    "- emojis are not purged\n",
    "- it failed to separate contractions (we've, haven't)...\n",
    "- it failed to separate words with punctuation in the middle (e-mail, anti-vax, a point after a word with no space, etc)\n",
    "- it failed to remove extremely common words (we've, us, etc)\n",
    "- it failed to discern other languages (spanish, notably)\n",
    "\n",
    "Can you improve the function so that it takes care of these? \n",
    "\n",
    "Hints: \n",
    "- Emojis are ususally considered unicodes by python. They can be purged with regular expressions : try `[\\U00010000-\\U0010FFFF]`\n",
    "- For contractions, try to spilt further by the apostrophe '\n",
    "- For Spanish, try a language recogniser. (check out what is imported in the intro! )\n",
    "- also purging some other extremely common stopwords might be a good idea. here is my list : \n",
    "\n",
    "`extra_stopwords = ['us', 'we', 've', 'i', 'you', 'he', 'she', 'it', 'they', 'me', 'him', 'her', 'them', 'my', 'your', 'his', 'its', 'our', 'their', 'a', 'an', 'the', 'and', 'or', 'but', 'if', 'in', 'on', 'at', 'to', 'for', 'with', 'of', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'get', 'let']`\n",
    "\n",
    "\n",
    "You are welcomed (and encouarged) to fix problems that I didn't find!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b15d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1fae120",
   "metadata": {},
   "source": [
    "## Exercise 5: count dictionary \n",
    "\n",
    "Now, we would like to count the frequencies of different virtues keyword and store them as additional variables in the data frame `all_tweets`. \n",
    "\n",
    "1. Create a function called `count_virtue` that would count that takes a category of virtue or vice (e.g. `\"care.virtue\"`) and return a count of the # of occurences of any virtue key word in the tweet. \n",
    "2. Apply it to the tweets for each virtue and vice, and add them to the variable as additional columns (e.g. `count_care_virtue`)\n",
    "\n",
    "Hints: \n",
    "\n",
    "- Try to make your function self-contained; the data frame `all_tweets` and the dictionary `mfd` should not be pulled from the global environment but rather given as inputs. \n",
    "- If your function counts at the level of a single string, the function `apply` is your friend. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600aa61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aaa32af",
   "metadata": {},
   "source": [
    "## Exercise 6: Who says it more? \n",
    "\n",
    "Finally, we would like to test the hypothesis that democrats emphasizes more the care and fairness virtures, while Republicans (Trump here) emphasizes more authority and in-groupness. Of course, we must normalize by the total sum of tweets - trump is just tweeting more than other people! \n",
    "\n",
    "Use pandas' `.groupby` and `.agg` functions to calculate the mean number of words about a virtue or vice per tweet emitted by each candidate/year. What do you think? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872349cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84ae8f58",
   "metadata": {},
   "source": [
    "## Save your pre-processed database as a .parquet \n",
    "\n",
    "Please save the columns `candidate`,  `year` , `original_text` and `processed_text` in a parquet document called \"`cooked_data.parquet`\" in the folder `data`. and the mfd dataframe as `cooked_mfd.parquet` in the same place. \n",
    "\n",
    "We will keep using this data for the next class! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a22d3b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a path \n",
    "path_cooked_data = this_dir / \"data\" / \"cooked_data.parquet\"\n",
    "\n",
    "all_tweets[['candidate','year','original_text', 'processed_text']].to_parquet(path_cooked_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d7b436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for mfd\n",
    "path_mfd_cooked = this_dir / \"data\" / \"cooked_mfd.parquet\"\n",
    "mfd.to_parquet(path_mfd_cooked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b50b59f",
   "metadata": {},
   "source": [
    "### If you still have time: Try other things we did in class!\n",
    "\n",
    "If you still have some time at hand, please try the other things we mentioned today: \n",
    "- Sentiment analysis: calculate a positivity score for each tweet and aggregate. Which candidate is the most positive one ?\n",
    "- Part-of-Speech; try Named entity recogination on some tweets and see what entity (e.g. \"Donald Trump\" \"The Fed\" \"2016\") are highlighted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90134b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
